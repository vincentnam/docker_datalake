version: '3'
services:
  datalake_input_swift:
#    image : morrisjobke/docker-swift-onlyone
    build : ./docker_build/docker-swift-onlyone/.
    ports :
      - '12345:8080'
      # 8080 : port d'authentification de Swift
    networks:
      northbound_airflow:
        aliases:
            - swift

  datalake_input_metadatabase:
    image : mongo
    ports:
      # HOST_PORT : CONTAINER_PORT
      - '27017:27017'
    networks:
      northbound_airflow:
        aliases:
            - metadatabase
  datalake_middleware_airflow :
#    image : puckel/docker-airflow
    build :
      context: docker_build/docker-airflow/.
      dockerfile: Dockerfile
      args:
        AIRFLOW_DEPS: "datadog,dask"
        PYTHON_DEPS: "flask_oauthlib>=0.9"
    ports:
      - '8080:8080'
    volumes :
      - ./apache_airflow:/usr/local/airflow
    command: webserver
    networks:
      northbound_airflow:
        aliases:
            - airflow
      southbound_airflow:
        aliases:
             - airflow

  datalake_goldzone_neo4j :
    image: neo4j
    volumes:
      - ./neo4j/data:/data
    ports:
    - '7474:7474'
    - '7687:7687'
    networks:
      southbound_airflow:
        aliases:
            - neo4j_gold
    environment:
      - NEO4J_AUTH=none
  datalake_goldzone_influxdb :
    image: influxdb
    volumes:
      - ./influxdb/data:/data
    ports:
    - '8086:8086'
    networks:
      southbound_airflow:
        aliases:
            - influxdb_gold




networks:
  northbound_airflow:
    driver: bridge
  southbound_airflow:
    driver: bridge

# TODO : Ajouter une base d'historique des jobs d'intégration de données